{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Foundation Model Prompt Engineering: Text2Text Generation\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "tags": []
      },
      "source": [
       "For this lab, we are going to be using a pre-hosted AI21Labs Jurrasic Mid model for the various prompting scenarios. The URL below points to an API pointing to a sagemaker model endpoint running Jurrasic Mid. \n",
       "\n",
       "If you wish to try the prompts against your own endpoint simply deploy an instance of Jurrasic model variant..\n",
       "\n",
       "Happy Prompting! "
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "import logging\n",
       "import json\n",
       "import time\n",
       "import boto3\n",
       "\n",
       "import matplotlib.pyplot as plt\n",
       "import numpy as np\n",
       "import requests\n",
       "from tqdm.contrib.concurrent import thread_map\n",
       "\n",
       "region = boto3.Session().region_name\n",
       "\n",
       "logger = logging.getLogger('sagemaker')\n",
       "logger.setLevel(logging.DEBUG)\n",
       "logger.addHandler(logging.StreamHandler())\n",
       "#url = \"https://yyosweaa3e.execute-api.us-east-1.amazonaws.com/LATEST/HF\"\n",
       "url = \"https://nm3yyjazj1.execute-api.us-east-1.amazonaws.com/Prod/invoke\""
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "def query_endpoint_with_json_payload(url, payload):\n",
       "    response = requests.post(\n",
       "        url,\n",
       "        json=payload,\n",
       "    )\n",
       "    #print(payload)\n",
       "    return response\n",
       "\n",
       "def parse_response_multiple_texts(query_response):\n",
       "    model_predictions = query_response.json()\n",
       "    #print(query_response)\n",
       "    generated_text = model_predictions['message']\n",
       "    return generated_text"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Advanced features\n",
       "\n",
       "***\n",
       "This model also supports many advanced parameters while performing inference. They include:\n",
       "\n",
       "* **max_length:** Model generates text until the output length (which includes the input context length) reaches `max_length`. If specified, it must be a positive integer.\n",
       "* **num_return_sequences:** Number of output sequences returned. If specified, it must be a positive integer.\n",
       "* **num_beams:** Number of beams used in the greedy search. If specified, it must be integer greater than or equal to `num_return_sequences`.\n",
       "* **no_repeat_ngram_size:** Model ensures that a sequence of words of `no_repeat_ngram_size` is not repeated in the output sequence. If specified, it must be a positive integer greater than 1.\n",
       "* **temperature:** Controls the randomness in the output. Higher temperature results in output sequence with low-probability words and lower temperature results in output sequence with high-probability words. If `temperature` -> 0, it results in greedy decoding. If specified, it must be a positive float.\n",
       "* **early_stopping:** If True, text generation is finished when all beam hypotheses reach the end of sentence token. If specified, it must be boolean.\n",
       "* **do_sample:** If True, sample the next word as per the likelihood. If specified, it must be boolean.\n",
       "* **top_k:** In each step of text generation, sample from only the `top_k` most likely words. If specified, it must be a positive integer.\n",
       "* **top_p:** In each step of text generation, sample from the smallest possible set of words with cumulative probability `top_p`. If specified, it must be a float between 0 and 1.\n",
       "* **seed:** Fix the randomized state for reproducibility. If specified, it must be an integer.\n",
       "\n",
       "We may specify any subset of the parameters mentioned above while invoking an endpoint. Next, we show an example of how to invoke endpoint with these arguments\n",
       "\n",
       "***"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## N-shot Learning via In-context Learning"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "Let's put in some example input text. You can put any text containing the task, the model returns the output of the accomplished task.\n",
       "\n",
       "Payload must be a json"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### A. Zero-shot Learning"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Text summarisation - generate text and summarise text, Use cases: creating articles, writing product descriptions, etc"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Example 1 - Generate text"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "instruction = 'Explain Australiaâ€™s foreign policy'\n",
       "\n",
       "prompt = instruction\n",
       "\n",
       "print(f'Prompt: {prompt}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = {\"prompt\":prompt, \"max_token\":100, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "#llm_response = response.json()[\"message\"]\n",
       "#print(llm_response)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'Generated text: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "tags": []
      },
      "source": [
       "#### Example 2 - Text summarisation"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "context = generated_text\n",
       "print(f'Context: \\n{context}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "instruction = \"Explain the above in one sentence\"\n",
       "\n",
       "prompt = f'{context}\\n{instruction}:'\n",
       "print(f'Prompt: {prompt}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = {\"prompt\":prompt, \"max_token\":100, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'Generated text: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Sentiment Analysis/Classification"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Example 3: generate text, product description"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "instruction = \"Generate a concise product description for the product: laptop.\"\n",
       "\n",
       "prompt = f'{instruction}:'\n",
       "print(f'Prompt: {prompt}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = {\"prompt\":prompt, \"max_token\":100, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'Generated text: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "tags": []
      },
      "source": [
       "#### Example 4: Lets control the output of product description, indicating the sections you would like the model to generate"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "instruction = \"Generate a concise product description for the product: laptop.\"\n",
       "output_indicator = \"Use the following format: Hook, Solution, Features and Benefits, Call to Action.\"\n",
       "\n",
       "prompt = f'{instruction}\\n{output_indicator}'\n",
       "print(f'Prompt: {prompt}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = {\"prompt\":prompt, \"max_token\":100, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'Generated text: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2. Information extraction: Extract keywords, location, people, sentiment. Use cases: SEO, metadata extraction\n",
       "\n",
       "The example is an excerpt from the article : https://www.sbs.com.au/news/article/anthony-albanese-to-hold-talks-with-joe-biden-and-rishi-sunak-on-aukus-defence-pact/0ar8pshdb\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Extract location from the article"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "article_context = \"US President Joe Biden will host leaders of Australia and the United Kingdom \\\n",
       "in San Diego next week to chart a way forward for the provision of nuclear-powered submarines and \\\n",
       "other high-tech weaponry to Australia, sources familiar with the plans said. \\\n",
       "The spokesperson for UK Prime Minister Rishi Sunak said he will visit the United States on Monday \\\n",
       "to meet Mr Biden and Prime Minister Anthony Albanese for talks on the AUKUS defence agreement.\"\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "instruction = \"List the locations mentioned in the paragraph above:\"\n",
       "\n",
       "prompt = f'{article_context}\\n{instruction}'\n",
       "print(f'Prompt: {prompt}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = {\"prompt\":prompt, \"max_token\":100, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'Locations: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Extract people from the article"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "instruction = \"List the people mentioned in the paragraph above:\"\n",
       "\n",
       "prompt = f'{article_context}\\n{instruction}'\n",
       "print(f'Prompt: {prompt}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = {\"prompt\":prompt, \"max_token\":100, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'People mentined in the article: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Extract keywords from the article"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "instruction = \"Extract keywords from the paragraph above:\"\n",
       "\n",
       "prompt = f'{article_context}\\n{instruction}'\n",
       "print(f'Prompt: {prompt}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = {\"prompt\":prompt, \"max_token\":100, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'Keywords in the article: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Extract sentiment from the article"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "article_context = 'Prime Minister Anthony Albanese is expected to announce Australias pathway to getting nuclear-powered subs in San Diego on Tuesday (AEDT) alongside Mr Biden and Mr Sunak. He will then hold bilateral meetings with both. \\\n",
       "\"This is a joint arrangement between Australia, the United States, and the United Kingdom,\" he told reporters on Thursday during a visit to India. \\\n",
       "\"We are great friends. We have over a century of standing side by side during peacetime and during conflict.'\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "instruction = \"What is the sentiment in the paragraph above? Reply as Neutral, Positive, or Negative only\"\n",
       "\n",
       "prompt = f'{article_context}\\n\\n{instruction}'\n",
       "print(f'Prompt: {prompt}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = {\"prompt\":prompt, \"max_token\":100, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'Sentiment of the article: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 3. Question answering from the article"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "article_context = \"Novak Djokovic reaches record 23 grand slam titles after French Open final win\\n\\nSerb beats Casper Ruud 7-6 (1), 6-3, 7-5 at Roland Garros\\nDjokovic now has one more grand slam title than Rafael Nadal\\n\\nSince his emergence at the top level of professional tennis 18 years ago, Novak Djokovic has used the dizzying bar set by Roger Federer and Rafael Nadal before him as inspiration to push himself to his limits, never doubting that he would one day rise above it.\\n\\nWhat once seemed impossible eventually became inevitable. On Sunday, Djokovic finally surpassed his great rivals in the most significant category of all as he defeated Casper Ruud 7-6 (1), 6-3, 7-5 to clinch his 23rd grand slam title, breaking his tie of 22 with Nadal.\\n\""
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "question = \"Whom did Djokovic defeat and what was the score?\""
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "prompt = f'{article_context}\\n{question}'\n",
       "print(f'Prompt: {prompt}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = {\"prompt\":prompt, \"max_token\":100, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'Answer: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 4. K-Shot prompt example"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Example - Lets check the model output without providing the examples of what we expect the model to respond back"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "prompt = f\"\"\"\n",
       "Review: \"I really had fun watching this movie\"\n",
       "This review is:\n",
       "\n",
       "\"\"\"\n",
       "print(f'Prompt: {prompt}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = {\"prompt\":prompt, \"max_token\":100, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'Answer: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "tags": []
      },
      "source": [
       "#### Example 2: \n",
       "As you can see above, we might expect the model to respond back with positive, nuetral or negative.\n",
       "But it does not and responds back with a more generic outputlets see how we can provide some examples to the model on what we expect "
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "prompt = f\"\"\"\n",
       "\n",
       "Review: \"I loved this movie!\"\n",
       "This review is positive.\n",
       "\n",
       "Review: \"I am not sure, I think the movie was fine.\"\n",
       "The review is neutral.\n",
       "\n",
       "Review: \"This movie was a waste of time and money.\"\n",
       "This review is negative.\n",
       "\n",
       "Review: \"I really had fun watching this movie\"\n",
       "This review is:\n",
       "\n",
       "\"\"\"\n",
       "print(f'Prompt: {prompt}')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = {\"prompt\":prompt, \"max_token\":100, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'Answer: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Challenge 1: Create a personalised email for a customer \n",
       "\n",
       "Create an email for a customer based on recommended movies they can watch as well as customer profile information. Let us for a moment pretend that we have made an API call to our CRM and know about the customer profile. The sample below shows a json payload of customer profile. \n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "customer_data = {\n",
       "    \"name\":\"Peter\"\n",
       "    \"age\":\"30\"\n",
       "    \"genre\":[\"Fantasy\", \"Sci-Fi\",\"Action\"]\n",
       "}"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "tags": []
      },
      "source": [
       "Now let us pretend that we have a list of movie recommendations returned by Amazon Personalize recomemmender system. If you wish to find out more about Amazon Personalize on this link - https://aws.amazon.com/personalize/. "
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "recommendations = {\n",
       "    \"movies\":\n",
       "        [\n",
       "            {\n",
       "                \"title\":\"Lord of the rings\",\n",
       "                \"synopsis\":\"A meek Hobbit from the Shire and eight companions set out on a journey to destroy the powerful One Ring and save Middle-earth from the Dark Lord Sauron.\"\n",
       "            },\n",
       "            {\n",
       "                \"title\":\"India Jones and the Raiders of the Lost Ark\",\n",
       "                \"synopsis\":\"Epic tale in which an intrepid archaeologist tries to beat a band of Nazis to a unique religious relic which is central to their plans for world domination. Battling against a snake phobia and a vengeful ex-girlfriend, Indiana Jones is in constant peril, making hair's-breadth escapes at every turn in this celebration of the innocent adventure movies of an earlier era.\"\n",
       "            },\n",
       "            {\n",
       "                \"title\":\"Star Wars Episode IV - A New Hope\",\n",
       "                \"synopsis\":\"The Imperial Forces -- under orders from cruel Darth Vader (David Prowse) -- hold Princess Leia (Carrie Fisher) hostage, in their efforts to quell the rebellion against the Galactic Empire. Luke Skywalker (Mark Hamill) and Han Solo (Harrison Ford), captain of the Millennium Falcon, work together with the companionable droid duo R2-D2 (Kenny Baker) and C-3PO (Anthony Daniels) to rescue the beautiful princess, help the Rebel Alliance, and restore freedom and justice to the Galaxy.\"\n",
       "            }\n",
       "        ]\n",
       "}"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "tags": []
      },
      "source": [
       "Below we are providing a sample prompt that you can use to create a prompt using the information to generate a personalised, and themed email copy created for the customer. The great thing about this approach is the ability to tailor emails for the individual so that not one customer receives the same email.\n",
       "\n",
       "The final prompt should look like the following. If you are struggling with the prompt or wish to avoid writing the code then simply copy and paste this prompt in the cell below and continue. - \n",
       "\n",
       "--------\n",
       "\n",
       "Peter is has an active subscription of ACME streaming service. He generaly watches Fantasy, Sci-fi and Action movies and titles. \n",
       "\n",
       "Write a detailed professional and perosnalized marketing email from ACME customer experience team addressing Peter recommendings the titles outlined below. Only recommend movie titles from below. Tailor the email to someone who enjoyes science fiction, action and fantasy genre. Mention in the email that Nagib can browse other titles from our vast library of on demand content. \n",
       "\n",
       "Movie Recommendations: \n",
       " \n",
       "Title: Lord of the rings\n",
       "Syponsis:  A meek Hobbit from the Shire and eight companions set out on a journey to destroy the powerful One Ring and save Middle-earth from the Dark Lord Sauron.\n",
       "\n",
       "Title: India Jones and the Raiders of the Lost Ark\n",
       "Sysponsis: Epic tale in which an intrepid archaeologist tries to beat a band of Nazis to a unique religious relic which is central to their plans for world domination. Battling against a snake phobia and a vengeful ex-girlfriend, Indiana Jones is in constant peril, making hair's-breadth escapes at every turn in this celebration of the innocent adventure movies of an earlier era.\n",
       "\n",
       "Title: Star Wars Episode IV - A New Hope\n",
       "Syponsis: The Imperial Forces -- under orders from cruel Darth Vader (David Prowse) -- hold Princess Leia (Carrie Fisher) hostage, in their efforts to quell the rebellion against the Galactic Empire. Luke Skywalker (Mark Hamill) and Han Solo (Harrison Ford), captain of the Millennium Falcon, work together with the companionable droid duo R2-D2 (Kenny Baker) and C-3PO (Anthony Daniels) to rescue the beautiful princess, help the Rebel Alliance, and restore freedom and justice to the Galaxy.\n",
       "\n",
       "---------\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "# TODO - complete the prompt to include the users detail as well as the recommendations. Do not forget to ask the LLM to write you an email copy. \n",
       "prompt = \"\"\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "Now that we have a prompt created with the necessary context + data, let us call the LLM to get the email copy. "
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "payload = payload = {\"prompt\":prompt, \"max_token\":200, \"temperature\": 0.5}\n",
       "response = query_endpoint_with_json_payload(url, payload)\n",
       "generated_text = parse_response_multiple_texts(response)\n",
       "print(f'Answer: \\n{generated_text}')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "tags": []
      },
      "source": [
       "## Challenge 2: Text 2 Image Challenge using Stable Diffusion \n",
       "\n",
       "We can use stable diffusion to create stock images that can accompany freshly authored articles without having to pay for licensing and copyright. Since all images are created using the generative AI model we can use for various types of publications. \n",
       "\n",
       "Let us pretend, there is an article published on \"Green cities\". If you are after a more realistic scenario please view this article - \n",
       "https://www.smh.com.au/traveller/reviews-and-advice/green-cities-10-major-cities-embracing-green-space-sustainability-and-renewable-energy-20221118-h27yle.html \n",
       "\n",
       "Our objective us to create a green city image that we can use as concept image for the article. Here are some sample prompts that we have used in our tests - \n",
       "\n",
       "Prompt: \n",
       "    beautiful and ultra realistic Paris city landscape dotted with rooftop gardens, tree-sprouting buildings and landmarks, Arc de triomphe, eiffel tower, Greentech, green cities walkable cities, sprawling plant life, an abundance of sunshine, Art Nouveau, Green architecture, towering vertical forests, Renewable energies, solar power, rainwater harvesting, self-sustainable community gardening, decentralized technologies, beautiful clear sunny day. - photo realistic, high quality, 4k, ultra realistic\n",
       "\n",
       "Negative Prompt: \n",
       "    monochrome, grayscale, cartoon, oil painting, painting, animated\n",
       "    \n",
       "\n",
       "\n",
       "Use the above as inspirations to create your own style and imagery. Use the stable diffision endpoint that you deployed earlier. "
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "availableInstances": [
      {
       "_defaultOrder": 0,
       "_isFastLaunch": true,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 4,
       "name": "ml.t3.medium",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 1,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 8,
       "name": "ml.t3.large",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 2,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.t3.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 3,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.t3.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 4,
       "_isFastLaunch": true,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 8,
       "name": "ml.m5.large",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 5,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.m5.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 6,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.m5.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 7,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 64,
       "name": "ml.m5.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 8,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 128,
       "name": "ml.m5.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 9,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 192,
       "name": "ml.m5.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 10,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 256,
       "name": "ml.m5.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 11,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 384,
       "name": "ml.m5.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 12,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 8,
       "name": "ml.m5d.large",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 13,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.m5d.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 14,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.m5d.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 15,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 64,
       "name": "ml.m5d.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 16,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 128,
       "name": "ml.m5d.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 17,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 192,
       "name": "ml.m5d.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 18,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 256,
       "name": "ml.m5d.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 19,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 384,
       "name": "ml.m5d.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 20,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": true,
       "memoryGiB": 0,
       "name": "ml.geospatial.interactive",
       "supportedImageNames": [
        "sagemaker-geospatial-v1-0"
       ],
       "vcpuNum": 0
      },
      {
       "_defaultOrder": 21,
       "_isFastLaunch": true,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 4,
       "name": "ml.c5.large",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 22,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 8,
       "name": "ml.c5.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 23,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.c5.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 24,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.c5.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 25,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 72,
       "name": "ml.c5.9xlarge",
       "vcpuNum": 36
      },
      {
       "_defaultOrder": 26,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 96,
       "name": "ml.c5.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 27,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 144,
       "name": "ml.c5.18xlarge",
       "vcpuNum": 72
      },
      {
       "_defaultOrder": 28,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 192,
       "name": "ml.c5.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 29,
       "_isFastLaunch": true,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.g4dn.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 30,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.g4dn.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 31,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 64,
       "name": "ml.g4dn.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 32,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 128,
       "name": "ml.g4dn.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 33,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 4,
       "hideHardwareSpecs": false,
       "memoryGiB": 192,
       "name": "ml.g4dn.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 34,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 256,
       "name": "ml.g4dn.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 35,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 61,
       "name": "ml.p3.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 36,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 4,
       "hideHardwareSpecs": false,
       "memoryGiB": 244,
       "name": "ml.p3.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 37,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 8,
       "hideHardwareSpecs": false,
       "memoryGiB": 488,
       "name": "ml.p3.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 38,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 8,
       "hideHardwareSpecs": false,
       "memoryGiB": 768,
       "name": "ml.p3dn.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 39,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.r5.large",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 40,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.r5.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 41,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 64,
       "name": "ml.r5.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 42,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 128,
       "name": "ml.r5.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 43,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 256,
       "name": "ml.r5.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 44,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 384,
       "name": "ml.r5.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 45,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 512,
       "name": "ml.r5.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 46,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 768,
       "name": "ml.r5.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 47,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.g5.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 48,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.g5.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 49,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 64,
       "name": "ml.g5.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 50,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 128,
       "name": "ml.g5.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 51,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 256,
       "name": "ml.g5.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 52,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 4,
       "hideHardwareSpecs": false,
       "memoryGiB": 192,
       "name": "ml.g5.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 53,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 4,
       "hideHardwareSpecs": false,
       "memoryGiB": 384,
       "name": "ml.g5.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 54,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 8,
       "hideHardwareSpecs": false,
       "memoryGiB": 768,
       "name": "ml.g5.48xlarge",
       "vcpuNum": 192
      },
      {
       "_defaultOrder": 55,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 8,
       "hideHardwareSpecs": false,
       "memoryGiB": 1152,
       "name": "ml.p4d.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 56,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 8,
       "hideHardwareSpecs": false,
       "memoryGiB": 1152,
       "name": "ml.p4de.24xlarge",
       "vcpuNum": 96
      }
     ],
     "instance_type": "ml.t3.medium",
     "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }
   